{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 208s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 activation=\"elu\",\n",
    "                                 kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### callbacks (early stopping, model checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 4.2130 - accuracy: 0.1660 - val_loss: 2.1554 - val_accuracy: 0.2294\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.0640 - accuracy: 0.2488 - val_loss: 2.0648 - val_accuracy: 0.2400\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.9457 - accuracy: 0.2902 - val_loss: 1.9147 - val_accuracy: 0.3012\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.8674 - accuracy: 0.3158 - val_loss: 1.8806 - val_accuracy: 0.3162\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.8027 - accuracy: 0.3425 - val_loss: 1.8651 - val_accuracy: 0.3206\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.7484 - accuracy: 0.3672 - val_loss: 1.7450 - val_accuracy: 0.3696\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.7000 - accuracy: 0.3827 - val_loss: 1.7038 - val_accuracy: 0.3804\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6591 - accuracy: 0.4011 - val_loss: 1.6491 - val_accuracy: 0.4006\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6312 - accuracy: 0.4094 - val_loss: 1.6613 - val_accuracy: 0.3884\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6048 - accuracy: 0.4214 - val_loss: 1.6477 - val_accuracy: 0.4034\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5780 - accuracy: 0.4315 - val_loss: 1.6571 - val_accuracy: 0.3996\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5601 - accuracy: 0.4380 - val_loss: 1.6051 - val_accuracy: 0.4210\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5405 - accuracy: 0.4468 - val_loss: 1.6458 - val_accuracy: 0.4010\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5227 - accuracy: 0.4540 - val_loss: 1.5851 - val_accuracy: 0.4254\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5051 - accuracy: 0.4615 - val_loss: 1.5763 - val_accuracy: 0.4300\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4891 - accuracy: 0.4650 - val_loss: 1.5753 - val_accuracy: 0.4212\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4798 - accuracy: 0.4697 - val_loss: 1.5772 - val_accuracy: 0.4402\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4676 - accuracy: 0.4747 - val_loss: 1.5422 - val_accuracy: 0.4524\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4537 - accuracy: 0.4764 - val_loss: 1.5736 - val_accuracy: 0.4328\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4433 - accuracy: 0.4808 - val_loss: 1.5362 - val_accuracy: 0.4484\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4287 - accuracy: 0.4860 - val_loss: 1.5581 - val_accuracy: 0.4478\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4174 - accuracy: 0.4910 - val_loss: 1.5505 - val_accuracy: 0.4472\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4063 - accuracy: 0.4962 - val_loss: 1.5489 - val_accuracy: 0.4496\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3924 - accuracy: 0.4999 - val_loss: 1.5032 - val_accuracy: 0.4648\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3857 - accuracy: 0.5026 - val_loss: 1.5328 - val_accuracy: 0.4544\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3724 - accuracy: 0.5066 - val_loss: 1.5533 - val_accuracy: 0.4486\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3641 - accuracy: 0.5087 - val_loss: 1.5321 - val_accuracy: 0.4586\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3572 - accuracy: 0.5139 - val_loss: 1.5477 - val_accuracy: 0.4506\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3486 - accuracy: 0.5159 - val_loss: 1.5095 - val_accuracy: 0.4668\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3370 - accuracy: 0.5211 - val_loss: 1.5382 - val_accuracy: 0.4644\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3317 - accuracy: 0.5209 - val_loss: 1.5432 - val_accuracy: 0.4572\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3229 - accuracy: 0.5227 - val_loss: 1.5374 - val_accuracy: 0.4656\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3138 - accuracy: 0.5280 - val_loss: 1.5190 - val_accuracy: 0.4650\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3066 - accuracy: 0.5300 - val_loss: 1.5892 - val_accuracy: 0.4508\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3022 - accuracy: 0.5322 - val_loss: 1.5592 - val_accuracy: 0.4508\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2928 - accuracy: 0.5360 - val_loss: 1.5383 - val_accuracy: 0.4598\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2813 - accuracy: 0.5411 - val_loss: 1.5069 - val_accuracy: 0.4720\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2757 - accuracy: 0.5419 - val_loss: 1.5132 - val_accuracy: 0.4674\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2648 - accuracy: 0.5438 - val_loss: 1.5083 - val_accuracy: 0.4726\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2570 - accuracy: 0.5481 - val_loss: 1.5298 - val_accuracy: 0.4680\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2517 - accuracy: 0.5476 - val_loss: 1.5388 - val_accuracy: 0.4618\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2440 - accuracy: 0.5538 - val_loss: 1.5194 - val_accuracy: 0.4714\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2371 - accuracy: 0.5562 - val_loss: 1.5594 - val_accuracy: 0.4656\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2298 - accuracy: 0.5595 - val_loss: 1.5759 - val_accuracy: 0.4550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22d2faf1d08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5032 - accuracy: 0.4648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5032280683517456, 0.46480000019073486]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 11:42 - loss: 2.8693 - accuracy: 0.1094WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.502919). Check your callbacks.\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.8405 - accuracy: 0.3415 - val_loss: 1.6922 - val_accuracy: 0.4030\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.6685 - accuracy: 0.4045 - val_loss: 1.5868 - val_accuracy: 0.4324\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.5968 - accuracy: 0.4323 - val_loss: 1.5120 - val_accuracy: 0.4578\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.5500 - accuracy: 0.4457 - val_loss: 1.4961 - val_accuracy: 0.4628\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.5017 - accuracy: 0.4666 - val_loss: 1.4365 - val_accuracy: 0.4928\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4654 - accuracy: 0.4776 - val_loss: 1.4183 - val_accuracy: 0.4880\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4328 - accuracy: 0.4906 - val_loss: 1.4188 - val_accuracy: 0.4902\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4038 - accuracy: 0.5044 - val_loss: 1.3799 - val_accuracy: 0.5032\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3820 - accuracy: 0.5091 - val_loss: 1.3686 - val_accuracy: 0.5174\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3627 - accuracy: 0.5187 - val_loss: 1.3477 - val_accuracy: 0.5246\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3390 - accuracy: 0.5252 - val_loss: 1.3692 - val_accuracy: 0.5188\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3150 - accuracy: 0.5358 - val_loss: 1.3905 - val_accuracy: 0.5040\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2996 - accuracy: 0.5412 - val_loss: 1.3546 - val_accuracy: 0.5208\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2797 - accuracy: 0.5464 - val_loss: 1.3290 - val_accuracy: 0.5310\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2598 - accuracy: 0.5536 - val_loss: 1.3701 - val_accuracy: 0.5178\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2513 - accuracy: 0.5576 - val_loss: 1.3305 - val_accuracy: 0.5350\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2307 - accuracy: 0.5620 - val_loss: 1.3262 - val_accuracy: 0.5322\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2140 - accuracy: 0.5727 - val_loss: 1.3467 - val_accuracy: 0.5330\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2019 - accuracy: 0.5777 - val_loss: 1.3231 - val_accuracy: 0.5360\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1889 - accuracy: 0.5810 - val_loss: 1.3902 - val_accuracy: 0.5154\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1768 - accuracy: 0.5859 - val_loss: 1.3538 - val_accuracy: 0.5256\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1607 - accuracy: 0.5930 - val_loss: 1.3368 - val_accuracy: 0.5356\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1502 - accuracy: 0.5958 - val_loss: 1.3549 - val_accuracy: 0.5288\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1369 - accuracy: 0.5986 - val_loss: 1.3235 - val_accuracy: 0.5430\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1239 - accuracy: 0.6056 - val_loss: 1.3423 - val_accuracy: 0.5314\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1099 - accuracy: 0.6091 - val_loss: 1.3516 - val_accuracy: 0.5358\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0994 - accuracy: 0.6140 - val_loss: 1.3362 - val_accuracy: 0.5458\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0909 - accuracy: 0.6157 - val_loss: 1.3576 - val_accuracy: 0.5328\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0806 - accuracy: 0.6193 - val_loss: 1.3400 - val_accuracy: 0.5394\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0729 - accuracy: 0.6224 - val_loss: 1.3455 - val_accuracy: 0.5326\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0580 - accuracy: 0.6264 - val_loss: 1.3414 - val_accuracy: 0.5422\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0468 - accuracy: 0.6327 - val_loss: 1.3759 - val_accuracy: 0.5364\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0352 - accuracy: 0.6370 - val_loss: 1.3469 - val_accuracy: 0.5452\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0275 - accuracy: 0.6380 - val_loss: 1.3397 - val_accuracy: 0.5412\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0166 - accuracy: 0.6437 - val_loss: 1.3498 - val_accuracy: 0.5346\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0122 - accuracy: 0.6444 - val_loss: 1.3409 - val_accuracy: 0.5404\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9918 - accuracy: 0.6532 - val_loss: 1.3774 - val_accuracy: 0.5332\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9927 - accuracy: 0.6511 - val_loss: 1.3581 - val_accuracy: 0.5442\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9808 - accuracy: 0.6542 - val_loss: 1.3807 - val_accuracy: 0.5352\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 1.3231 - accuracy: 0.5360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3231035470962524, 0.5360000133514404]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 14:11 - loss: 3.0440 - accuracy: 0.1094WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.617268). Check your callbacks.\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.9451 - accuracy: 0.3021 - val_loss: 1.8620 - val_accuracy: 0.3352\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7210 - accuracy: 0.3877 - val_loss: 1.7397 - val_accuracy: 0.3904\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6180 - accuracy: 0.4287 - val_loss: 1.7237 - val_accuracy: 0.3930\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5502 - accuracy: 0.4527 - val_loss: 1.6405 - val_accuracy: 0.4314\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4881 - accuracy: 0.4741 - val_loss: 1.5681 - val_accuracy: 0.4496\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4380 - accuracy: 0.4972 - val_loss: 1.5565 - val_accuracy: 0.4598\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3979 - accuracy: 0.5127 - val_loss: 1.5250 - val_accuracy: 0.4546\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3569 - accuracy: 0.5255 - val_loss: 1.4834 - val_accuracy: 0.4788\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3216 - accuracy: 0.5385 - val_loss: 1.4822 - val_accuracy: 0.4772\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2906 - accuracy: 0.5529 - val_loss: 1.5064 - val_accuracy: 0.4876\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2599 - accuracy: 0.5649 - val_loss: 1.5498 - val_accuracy: 0.4868\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2391 - accuracy: 0.5739 - val_loss: 1.4684 - val_accuracy: 0.4912\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.2051 - accuracy: 0.5860 - val_loss: 1.4778 - val_accuracy: 0.5020\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1791 - accuracy: 0.5958 - val_loss: 1.4659 - val_accuracy: 0.5114\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1543 - accuracy: 0.6037 - val_loss: 1.5204 - val_accuracy: 0.5060\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1339 - accuracy: 0.6108 - val_loss: 1.5405 - val_accuracy: 0.5104\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1178 - accuracy: 0.6178 - val_loss: 1.4978 - val_accuracy: 0.5090\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2008 - accuracy: 0.5987 - val_loss: 1.7512 - val_accuracy: 0.3802\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3431 - accuracy: 0.5312 - val_loss: 1.5624 - val_accuracy: 0.4830\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1726 - accuracy: 0.5948 - val_loss: 1.5455 - val_accuracy: 0.4946\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1025 - accuracy: 0.6190 - val_loss: 1.5492 - val_accuracy: 0.4856\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0632 - accuracy: 0.6376 - val_loss: 1.5358 - val_accuracy: 0.5086\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0350 - accuracy: 0.6447 - val_loss: 1.5311 - val_accuracy: 0.5046\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0256 - accuracy: 0.6508 - val_loss: 1.5642 - val_accuracy: 0.5028\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0187 - accuracy: 0.6532 - val_loss: 1.5221 - val_accuracy: 0.5126\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9929 - accuracy: 0.6614 - val_loss: 1.5579 - val_accuracy: 0.5134\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9997 - accuracy: 0.6595 - val_loss: 1.5266 - val_accuracy: 0.5126\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9778 - accuracy: 0.6671 - val_loss: 1.6028 - val_accuracy: 0.5046\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9501 - accuracy: 0.6784 - val_loss: 1.5845 - val_accuracy: 0.5150\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3409 - accuracy: 0.6528 - val_loss: 1.5457 - val_accuracy: 0.4940\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9760 - accuracy: 0.6644 - val_loss: 1.5560 - val_accuracy: 0.5044\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9265 - accuracy: 0.6824 - val_loss: 1.6128 - val_accuracy: 0.5182\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8922 - accuracy: 0.6915 - val_loss: 34827.9883 - val_accuracy: 0.5144\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8663 - accuracy: 0.7060 - val_loss: 1.6203 - val_accuracy: 0.5074\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4659 - accuracy: 0.5114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.465861439704895, 0.5113999843597412]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - ETA: 0s - loss: 1.4700 - accuracy: 0.50 - 0s 2ms/step - loss: 1.4659 - accuracy: 0.5114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.465861439704895, 0.5113999843597412]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha dropout , MC dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 13:38 - loss: 2.9857 - accuracy: 0.0938WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.582688). Check your callbacks.\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8984 - accuracy: 0.3247 - val_loss: 1.8221 - val_accuracy: 0.3534\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6678 - accuracy: 0.4130 - val_loss: 1.6902 - val_accuracy: 0.4036\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.5795 - accuracy: 0.4476 - val_loss: 1.6495 - val_accuracy: 0.4198\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5132 - accuracy: 0.4668 - val_loss: 1.5818 - val_accuracy: 0.4572\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4477 - accuracy: 0.4937 - val_loss: 1.5930 - val_accuracy: 0.4670\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4020 - accuracy: 0.5081 - val_loss: 1.5108 - val_accuracy: 0.4882\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3606 - accuracy: 0.5275 - val_loss: 1.5762 - val_accuracy: 0.4768\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3145 - accuracy: 0.5446 - val_loss: 1.5447 - val_accuracy: 0.4892\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2857 - accuracy: 0.5570 - val_loss: 1.5522 - val_accuracy: 0.4890\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.2468 - accuracy: 0.5672 - val_loss: 1.5172 - val_accuracy: 0.5036\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.2168 - accuracy: 0.5791 - val_loss: 1.5378 - val_accuracy: 0.5094\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1935 - accuracy: 0.5907 - val_loss: 1.5396 - val_accuracy: 0.5006\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1536 - accuracy: 0.6053 - val_loss: 1.5783 - val_accuracy: 0.5016\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1310 - accuracy: 0.6116 - val_loss: 1.5120 - val_accuracy: 0.5114\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1082 - accuracy: 0.6214 - val_loss: 1.6271 - val_accuracy: 0.4930\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0800 - accuracy: 0.6318 - val_loss: 1.6298 - val_accuracy: 0.5220\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0527 - accuracy: 0.6401 - val_loss: 1.7097 - val_accuracy: 0.5018\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.0343 - accuracy: 0.6472 - val_loss: 1.6491 - val_accuracy: 0.5102\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0147 - accuracy: 0.6540 - val_loss: 1.6433 - val_accuracy: 0.5200\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9942 - accuracy: 0.6626 - val_loss: 1.7414 - val_accuracy: 0.5064\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9735 - accuracy: 0.6710 - val_loss: 1.7536 - val_accuracy: 0.5084\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9547 - accuracy: 0.6748 - val_loss: 1.6892 - val_accuracy: 0.5092\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9370 - accuracy: 0.6821 - val_loss: 1.6821 - val_accuracy: 0.5074\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9151 - accuracy: 0.6907 - val_loss: 1.7442 - val_accuracy: 0.5118\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9043 - accuracy: 0.6961 - val_loss: 1.8307 - val_accuracy: 0.5148\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8818 - accuracy: 0.7026 - val_loss: 1.8119 - val_accuracy: 0.4970\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5108 - accuracy: 0.4882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5107836723327637, 0.48820000886917114]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return np.argmax(Y_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4876"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1cycle scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=1e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "\n",
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.0605 - accuracy: 0.2827 - val_loss: 1.7523 - val_accuracy: 0.3842\n",
      "Epoch 2/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.7928 - accuracy: 0.3700 - val_loss: 1.6468 - val_accuracy: 0.4268\n",
      "Epoch 3/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.6657 - accuracy: 0.4127 - val_loss: 1.6190 - val_accuracy: 0.4260\n",
      "Epoch 4/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.5773 - accuracy: 0.4419 - val_loss: 1.5698 - val_accuracy: 0.4530\n",
      "Epoch 5/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.5116 - accuracy: 0.4643 - val_loss: 1.5651 - val_accuracy: 0.4502\n",
      "Epoch 6/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.4562 - accuracy: 0.4810 - val_loss: 1.5435 - val_accuracy: 0.4596\n",
      "Epoch 7/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.4118 - accuracy: 0.4981 - val_loss: 1.5522 - val_accuracy: 0.4638:  - ETA: 1s - loss: 1.4091 - accuracy: 0.49 - ETA: 1s\n",
      "Epoch 8/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.3737 - accuracy: 0.5143 - val_loss: 1.5305 - val_accuracy: 0.4724741 - \n",
      "Epoch 9/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.3394 - accuracy: 0.5258 - val_loss: 1.5578 - val_accuracy: 0.4682\n",
      "Epoch 10/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.3077 - accuracy: 0.5341 - val_loss: 1.5806 - val_accuracy: 0.4744- accura - ETA: 0s - loss: 1.3081 - accuracy: 0. - ETA: 0s - loss: 1.3085 - accuracy: 0.\n",
      "Epoch 11/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.2753 - accuracy: 0.5487 - val_loss: 1.5867 - val_accuracy: 0.4620\n",
      "Epoch 12/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.2498 - accuracy: 0.5571 - val_loss: 1.5449 - val_accuracy: 0.4824\n",
      "Epoch 13/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.2232 - accuracy: 0.5645 - val_loss: 1.6411 - val_accuracy: 0.4634\n",
      "Epoch 14/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.1987 - accuracy: 0.5734 - val_loss: 1.6347 - val_accuracy: 0.4716\n",
      "Epoch 15/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.1787 - accuracy: 0.5768 - val_loss: 1.6089 - val_accuracy: 0.4746 - loss: - ETA: 0s - loss: 1.1705 - accuracy: 0.58 - ETA: 0s - loss:\n",
      "Epoch 16/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.1560 - accuracy: 0.5887 - val_loss: 1.7168 - val_accuracy: 0.4680\n",
      "Epoch 17/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.1371 - accuracy: 0.5957 - val_loss: 1.5748 - val_accuracy: 0.4968\n",
      "Epoch 18/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.1157 - accuracy: 0.6044 - val_loss: 1.6085 - val_accuracy: 0.4856\n",
      "Epoch 19/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0971 - accuracy: 0.6092 - val_loss: 1.7401 - val_accuracy: 0.4800: 0s - loss: 1.0938 - accuracy: 0.61 - ETA: 0s - loss: 1.0930 - accura\n",
      "Epoch 20/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0728 - accuracy: 0.6160 - val_loss: 1.6462 - val_accuracy: 0.4792 1.0303 - accuracy - ETA: 1s - loss: 1.0438 -  - ETA: 1s - loss: 1.0531 - accuracy: 0. - ETA: 1s - l - ETA: 0s - loss: 1.0663 - \n",
      "Epoch 21/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0633 - accuracy: 0.6216 - val_loss: 1.6227 - val_accuracy: 0.4976\n",
      "Epoch 22/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0449 - accuracy: 0.6276 - val_loss: 1.6691 - val_accuracy: 0.4988s: 1.0427 - accuracy: 0.62 - ETA: 0s - loss: 1.0422 - accuracy: 0.62 - ETA: 0s - loss: 1.042\n",
      "Epoch 23/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0305 - accuracy: 0.6343 - val_loss: 1.7637 - val_accuracy: 0.47400  - ETA: 0s - loss: 1.0299 - accuracy: 0.\n",
      "Epoch 24/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0113 - accuracy: 0.6406 - val_loss: 1.6737 - val_accuracy: 0.4842\n",
      "Epoch 25/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0007 - accuracy: 0.6424 - val_loss: 1.7163 - val_accuracy: 0.4692\n",
      "Epoch 26/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.9881 - accuracy: 0.6489 - val_loss: 1.7332 - val_accuracy: 0.47422s - loss: 0.9388 - accu - ETA: 1s - loss: 0.9481 - accuracy:  - ETA: 0s - loss: 0.9782 - accuracy: 0.65 - ETA: 0s - loss: 0.9803 - accura\n",
      "Epoch 27/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.9763 - accuracy: 0.6525 - val_loss: 1.7649 - val_accuracy: 0.4792\n",
      "Epoch 28/100\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.9597 - accuracy: 0.6573 - val_loss: 1.6941 - val_accuracy: 0.4936\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "onecycle = OneCycleScheduler(len(X_train_scaled) // batch_size * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle,keras.callbacks.EarlyStopping(patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
